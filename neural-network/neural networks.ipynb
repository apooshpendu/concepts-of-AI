{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sealed-stand",
   "metadata": {},
   "source": [
    "### Feed-forward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-substance",
   "metadata": {},
   "source": [
    "An acyclic artificial neural network in which data moves in only one direction, i.e. forwardâ€”from the input nodes, through the hidden nodes (if any) and to the output nodes. It is the simplest form of artificial neural networks.\n",
    "\n",
    "In the example, we use 3-layer neural network with variable number of node in the hidden layer. The purpose of the model is to predict the quality of white wine using the wine dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "french-ready",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "import pickle, gzip\n",
    "import urllib.request\n",
    "\n",
    "import struct\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "fancy-superior",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable parameters\n",
    "n_h = 16;\n",
    "learning_rate = 0.01;\n",
    "epochs = 5000;\n",
    "validation_error = 0.01;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "sufficient-monte",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading dataset\n",
    "df = pd.read_csv(\"winequality-white.csv\", sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "advanced-compiler",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing dataset\n",
    "def normalize_dataset(ds):\n",
    "    result = ds.copy()\n",
    "    for feature_name in ds.columns:\n",
    "        max_value = ds[feature_name].max()\n",
    "        min_value = ds[feature_name].min()\n",
    "        result[feature_name] = (ds[feature_name] - min_value) / (max_value - min_value)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "lesser-contrary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.186275</td>\n",
       "      <td>0.216867</td>\n",
       "      <td>0.308282</td>\n",
       "      <td>0.106825</td>\n",
       "      <td>0.149826</td>\n",
       "      <td>0.373550</td>\n",
       "      <td>0.267785</td>\n",
       "      <td>0.254545</td>\n",
       "      <td>0.267442</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.240385</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>0.204819</td>\n",
       "      <td>0.015337</td>\n",
       "      <td>0.118694</td>\n",
       "      <td>0.041812</td>\n",
       "      <td>0.285383</td>\n",
       "      <td>0.132832</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.313953</td>\n",
       "      <td>0.241935</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.413462</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.240964</td>\n",
       "      <td>0.096626</td>\n",
       "      <td>0.121662</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.204176</td>\n",
       "      <td>0.154039</td>\n",
       "      <td>0.490909</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.338710</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.192771</td>\n",
       "      <td>0.121166</td>\n",
       "      <td>0.145401</td>\n",
       "      <td>0.156794</td>\n",
       "      <td>0.410673</td>\n",
       "      <td>0.163678</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>0.209302</td>\n",
       "      <td>0.306452</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.192771</td>\n",
       "      <td>0.121166</td>\n",
       "      <td>0.145401</td>\n",
       "      <td>0.156794</td>\n",
       "      <td>0.410673</td>\n",
       "      <td>0.163678</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>0.209302</td>\n",
       "      <td>0.306452</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0       0.307692          0.186275     0.216867        0.308282   0.106825   \n",
       "1       0.240385          0.215686     0.204819        0.015337   0.118694   \n",
       "2       0.413462          0.196078     0.240964        0.096626   0.121662   \n",
       "3       0.326923          0.147059     0.192771        0.121166   0.145401   \n",
       "4       0.326923          0.147059     0.192771        0.121166   0.145401   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide   density        pH  sulphates  \\\n",
       "0             0.149826              0.373550  0.267785  0.254545   0.267442   \n",
       "1             0.041812              0.285383  0.132832  0.527273   0.313953   \n",
       "2             0.097561              0.204176  0.154039  0.490909   0.255814   \n",
       "3             0.156794              0.410673  0.163678  0.427273   0.209302   \n",
       "4             0.156794              0.410673  0.163678  0.427273   0.209302   \n",
       "\n",
       "    alcohol  quality  \n",
       "0  0.129032      0.5  \n",
       "1  0.241935      0.5  \n",
       "2  0.338710      0.5  \n",
       "3  0.306452      0.5  \n",
       "4  0.306452      0.5  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_ds = normalize_dataset(df)\n",
    "wine_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "fewer-occasions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4898, 11) (4898,)\n"
     ]
    }
   ],
   "source": [
    "X = wine_ds.drop(['quality'], axis=1).values\n",
    "Y = wine_ds['quality'].values\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "perfect-palace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset into training and testing set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2,random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "prescription-elements",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing parameters\n",
    "def initialize_parameters(n_input, n_hidden, n_output):\n",
    "    \n",
    "    np.random.seed(1);\n",
    "    W1 = np.random.randn(n_h, n_input) * 0.01\n",
    "    b1 = np.zeros(shape=(n_h, 1))\n",
    "    W2 = np.random.randn(n_output, n_h) * 0.01\n",
    "    b2 = np.zeros(shape=(n_output, 1))\n",
    "    \n",
    "    parameters = {'W1': W1,\n",
    "                  'b1': b1,\n",
    "                  'W2': W2,\n",
    "                  'b2': b2};\n",
    "    \n",
    "    return parameters;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "median-reproduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating forward function\n",
    "def linear_function(X, W, b):\n",
    "    \n",
    "#    print(W.shape, ' || ', X.shape, ' || ', b.shape)\n",
    "    Z = W @ X + b;\n",
    "    cache = (X, W, b);\n",
    "    \n",
    "    return Z, cache;\n",
    "\n",
    "def sigmoid(Z):\n",
    "\n",
    "    Z = Z.astype('float64')\n",
    "    A = 1/(1+np.exp(-Z));\n",
    "    A_cache = (Z);\n",
    "    \n",
    "    return A, A_cache;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "japanese-missouri",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost function\n",
    "def cost_function(A, AL):\n",
    "    \n",
    "    J = 0.5 * np.square(AL - A);\n",
    "    return J;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "macro-screw",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Creating backward function\n",
    "def backward_function(dZ, cache):\n",
    "    \n",
    "    X_prev, W, b = cache\n",
    "    m = X_prev.shape[0];\n",
    "    \n",
    "    dW = 1 / m * np.dot(dZ, X_prev.T);\n",
    "    db = 1 / m * np.sum(dZ, axis=1, keepdims=True)\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    \n",
    "    return dA_prev, dW, db;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "million-fault",
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating weights and biases using gradient descent\n",
    "def gradient_descent(parameters, gradients, lr):\n",
    "    \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "   \n",
    "    dW1 = gradients['dW1']\n",
    "    db1 = gradients['db1']\n",
    "    dW2 = gradients['dW2']\n",
    "    db2 = gradients['db2']\n",
    "    W1 = W1 - lr * dW1\n",
    "    b1 = b1 - lr * db1\n",
    "    W2 = W2 - lr * dW2\n",
    "    b2 = b2 - lr * db2\n",
    "    \n",
    "    parameters = {\"W1\": W1, \"b1\": b1,\"W2\": W2,\"b2\": b2}\n",
    "    \n",
    "    return parameters;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "clinical-jimmy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(X, Y, parameters, hidden_layer_size):\n",
    "    \n",
    "    Z1, cache1 = linear_function(X.T, parameters['W1'], parameters['b1']);\n",
    "    A1, A1_cache = sigmoid(Z1);\n",
    "    Z2, cache2 = linear_function(A1, parameters['W2'], parameters['b2']);\n",
    "    A2, A2_cache = sigmoid(Z2);\n",
    "    \n",
    "    cost = cost_function(A2, Y);\n",
    "    \n",
    "    dZ2 = A2 - Y;\n",
    "    dA2_prev, dW2, db2 = backward_function(dZ2, cache2);\n",
    "    dZ1 = np.multiply(np.dot(parameters['W2'].T, dZ2), 1 - np.power(A1, 2));\n",
    "    dA1_prev, dW1, db1 = backward_function(dZ1, cache1);\n",
    "    \n",
    "    gradients = {\"dW1\": dW1,\n",
    "                  \"db1\": db1,\n",
    "                  \"dW2\": dW2,\n",
    "                  \"db2\": db2};\n",
    "    \n",
    "    return gradients, cost;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "spiritual-panic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model to update parameters using the training set\n",
    "def nn_model(X, Y, hl_size, learning_rate, epochs):\n",
    "    \n",
    "    parameters = initialize_parameters(X.shape[1], hl_size, 1);\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        gradients, cost = propagate(X, Y, parameters, hl_size)\n",
    "        parameters = gradient_descent(parameters, gradients, learning_rate)\n",
    "        \n",
    "        if i % 250 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, np.average(cost)))\n",
    "            \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "automatic-astrology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.010971\n",
      "Cost after iteration 250: 0.008811\n",
      "Cost after iteration 500: 0.008088\n",
      "Cost after iteration 750: 0.007854\n",
      "Cost after iteration 1000: 0.007786\n",
      "Cost after iteration 1250: 0.007763\n",
      "Cost after iteration 1500: 0.007754\n",
      "Cost after iteration 1750: 0.007749\n",
      "Cost after iteration 2000: 0.007747\n",
      "Cost after iteration 2250: 0.007744\n",
      "Cost after iteration 2500: 0.007743\n",
      "Cost after iteration 2750: 0.007741\n",
      "Cost after iteration 3000: 0.007740\n",
      "Cost after iteration 3250: 0.007739\n",
      "Cost after iteration 3500: 0.007738\n",
      "Cost after iteration 3750: 0.007736\n",
      "Cost after iteration 4000: 0.007735\n",
      "Cost after iteration 4250: 0.007734\n",
      "Cost after iteration 4500: 0.007733\n",
      "Cost after iteration 4750: 0.007733\n"
     ]
    }
   ],
   "source": [
    "parameters = nn_model(X_train, Y_train, n_h, learning_rate, epochs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "european-guest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model to predict the quality of wine using testing set\n",
    "def predict(X, Y, parameters):\n",
    "    Z1, cache1 = linear_function(X.T, parameters['W1'], parameters['b1']);\n",
    "    A1, A1_cache = sigmoid(Z1);\n",
    "    Z2, cache2 = linear_function(A1, parameters['W2'], parameters['b2']);\n",
    "    A2, A2_cache = sigmoid(Z2);\n",
    "    \n",
    "    prediction = np.round(A2);\n",
    "    \n",
    "    accuracy = np.dot(Y, prediction.T) + np.dot(1 - Y, 1 - prediction.T);\n",
    "    \n",
    "    return (accuracy / Y.size) * 100;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "surrounded-morris",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: [56.41156463]\n"
     ]
    }
   ],
   "source": [
    "accuracy = predict(X_test, Y_test, parameters);\n",
    "print(\"Accuracy: {0}\".format(accuracy));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-electronics",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-roots",
   "metadata": {},
   "source": [
    "A class of deep neural networks that is most commonly applied to analyzing visual imagery. It is a regularized versin of multi-layer perceptron that takes advantage of the hierarchical pattern in data and assembles more complex patterns using smaller and simpler patterns.\n",
    "\n",
    "In the example, we use application of handwritten digit recognition using MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "affiliated-honolulu",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "skilled-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable parameters\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "strategic-witch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "vertical-juvenile",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting input shape to match the shape in kernel\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "crude-connecticut",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 training samples\n",
      "10000 testing samples\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'training samples')\n",
    "print(x_test.shape[0], 'testing samples')\n",
    "\n",
    "# Converting class vectors to binary class matrices\n",
    "y_train = tensorflow.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tensorflow.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "matched-invasion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 6)         60        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 16)        880       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 120)               48120     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 60,074\n",
      "Trainable params: 60,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(6, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(84, activation='relu'))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ideal-webmaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding loss and optimier function in the model\n",
    "model.compile(loss=tensorflow.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tensorflow.keras.optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "neither-bullet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 2.3012 - accuracy: 0.1120 - val_loss: 2.2994 - val_accuracy: 0.1135\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 6s 93us/sample - loss: 2.2372 - accuracy: 0.1736 - val_loss: 1.5975 - val_accuracy: 0.4569\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 6s 93us/sample - loss: 0.6786 - accuracy: 0.7790 - val_loss: 0.3849 - val_accuracy: 0.8799\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.3190 - accuracy: 0.9028 - val_loss: 0.2399 - val_accuracy: 0.9247\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.2186 - accuracy: 0.9320 - val_loss: 0.1750 - val_accuracy: 0.9450\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.1639 - accuracy: 0.9496 - val_loss: 0.1591 - val_accuracy: 0.9490\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.1329 - accuracy: 0.9594 - val_loss: 0.1223 - val_accuracy: 0.9612\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.1127 - accuracy: 0.9651 - val_loss: 0.1062 - val_accuracy: 0.9647\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 0.0982 - accuracy: 0.9689 - val_loss: 0.1049 - val_accuracy: 0.9656\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.0894 - accuracy: 0.9718 - val_loss: 0.0847 - val_accuracy: 0.9716\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 0.0811 - accuracy: 0.9744 - val_loss: 0.0762 - val_accuracy: 0.9750\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.0733 - accuracy: 0.9771 - val_loss: 0.0705 - val_accuracy: 0.9762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27793a806c8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model using the training dataset\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "graduate-temple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model using the testing dataset\n",
    "score = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "asian-ceremony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.07047177767213433\n",
      "Test accuracy: 0.9762\n"
     ]
    }
   ],
   "source": [
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-pension",
   "metadata": {},
   "source": [
    "### Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-brother",
   "metadata": {},
   "source": [
    "A class of artificial neural networks where connections between nodes form a directed graph along a temporal sequence. it uses its internal memory to process variable length sequences of input which makes it applicable to tasks such as unsegmented, connected handwriting recognition or speech recognition.\n",
    "\n",
    "We use RNN, especially LSTM, to generate music notes after training the model using existing notes in the form of MIDI dataset. LSTM is a type of RNN which has feddback connections to process entrie sequence of data instead of just a single data point. Each LSTM cell consist of three gates, viz. input gate, output gate and forget gate, that controls the flow of information in and out of the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "boxed-consumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import glob\n",
    "import pickle\n",
    "import numpy\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import BatchNormalization as BatchNorm\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "disabled-hobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing parameters\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "generated_note_size = 500\n",
    "\n",
    "data_path = \"rnn\"\n",
    "output_file = 'test_output.mid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "optimum-bible",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "def get_notes(data_path):\n",
    "    \"\"\" Get all the notes and chords from the midi files in the ./midi_songs directory \"\"\"\n",
    "    notes = []\n",
    "\n",
    "    for file in glob.glob(data_path + \"/midi_songs/*.mid\"):\n",
    "        midi = converter.parse(file)\n",
    "\n",
    "        print(\"Parsing %s\" % file)\n",
    "\n",
    "        notes_to_parse = None\n",
    "\n",
    "        try: # file has instrument parts\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = s2.parts[0].recurse() \n",
    "        except: # file has notes in a flat structure\n",
    "            notes_to_parse = midi.flat.notes\n",
    "\n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    with open(data_path + '/data/notes', 'wb') as filepath:\n",
    "        pickle.dump(notes, filepath)\n",
    "\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "downtown-peninsula",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing rnn/midi_songs\\0fithos.mid\n",
      "Parsing rnn/midi_songs\\8.mid\n",
      "Parsing rnn/midi_songs\\ahead_on_our_way_piano.mid\n",
      "Parsing rnn/midi_songs\\AT.mid\n",
      "Parsing rnn/midi_songs\\balamb.mid\n",
      "Parsing rnn/midi_songs\\bcm.mid\n",
      "Parsing rnn/midi_songs\\BlueStone_LastDungeon.mid\n",
      "Parsing rnn/midi_songs\\braska.mid\n",
      "Parsing rnn/midi_songs\\caitsith.mid\n",
      "Parsing rnn/midi_songs\\Cids.mid\n",
      "Parsing rnn/midi_songs\\cosmo.mid\n",
      "Parsing rnn/midi_songs\\costadsol.mid\n",
      "Parsing rnn/midi_songs\\dayafter.mid\n",
      "Parsing rnn/midi_songs\\decisive.mid\n",
      "Parsing rnn/midi_songs\\dontbeafraid.mid\n",
      "Parsing rnn/midi_songs\\DOS.mid\n",
      "Parsing rnn/midi_songs\\electric_de_chocobo.mid\n",
      "Parsing rnn/midi_songs\\Eternal_Harvest.mid\n",
      "Parsing rnn/midi_songs\\EyesOnMePiano.mid\n",
      "Parsing rnn/midi_songs\\ff11_awakening_piano.mid\n",
      "Parsing rnn/midi_songs\\ff1battp.mid\n",
      "Parsing rnn/midi_songs\\FF3_Battle_(Piano).mid\n",
      "Parsing rnn/midi_songs\\FF3_Third_Phase_Final_(Piano).mid\n",
      "Parsing rnn/midi_songs\\ff4-airship.mid\n",
      "Parsing rnn/midi_songs\\Ff4-BattleLust.mid\n",
      "Parsing rnn/midi_songs\\ff4-fight1.mid\n",
      "Parsing rnn/midi_songs\\ff4-town.mid\n",
      "Parsing rnn/midi_songs\\FF4.mid\n",
      "Parsing rnn/midi_songs\\ff4pclov.mid\n",
      "Parsing rnn/midi_songs\\ff4_piano_collections-main_theme.mid\n",
      "Parsing rnn/midi_songs\\FF6epitaph_piano.mid\n",
      "Parsing rnn/midi_songs\\ff6shap.mid\n",
      "Parsing rnn/midi_songs\\Ff7-Cinco.mid\n",
      "Parsing rnn/midi_songs\\Ff7-Jenova_Absolute.mid\n",
      "Parsing rnn/midi_songs\\ff7-mainmidi.mid\n",
      "Parsing rnn/midi_songs\\Ff7-One_Winged.mid\n",
      "Parsing rnn/midi_songs\\ff7themep.mid\n",
      "Parsing rnn/midi_songs\\ff8-lfp.mid\n",
      "Parsing rnn/midi_songs\\FF8_Shuffle_or_boogie_pc.mid\n",
      "Parsing rnn/midi_songs\\FFIII_Edgar_And_Sabin_Piano.mid\n",
      "Parsing rnn/midi_songs\\FFIXQuMarshP.mid\n",
      "Parsing rnn/midi_songs\\FFIX_Piano.mid\n",
      "Parsing rnn/midi_songs\\FFVII_BATTLE.mid\n",
      "Parsing rnn/midi_songs\\FFX_-_Ending_Theme_(Piano_Version)_-_by_Angel_FF.mid\n",
      "Parsing rnn/midi_songs\\Fiend_Battle_(Piano).mid\n",
      "Parsing rnn/midi_songs\\Fierce_Battle_(Piano).mid\n",
      "Parsing rnn/midi_songs\\figaro.mid\n",
      "Parsing rnn/midi_songs\\Finalfantasy5gilgameshp.mid\n",
      "Parsing rnn/midi_songs\\Finalfantasy6fanfarecomplete.mid\n",
      "Parsing rnn/midi_songs\\Final_Fantasy_7_-_Judgement_Day_Piano.mid\n",
      "Parsing rnn/midi_songs\\Final_Fantasy_Matouyas_Cave_Piano.mid\n",
      "Parsing rnn/midi_songs\\fortresscondor.mid\n",
      "Parsing rnn/midi_songs\\Fyw_piano.mid\n",
      "Parsing rnn/midi_songs\\gerudo.mid\n",
      "Parsing rnn/midi_songs\\goldsaucer.mid\n",
      "Parsing rnn/midi_songs\\Gold_Silver_Rival_Battle.mid\n",
      "Parsing rnn/midi_songs\\great_war.mid\n",
      "Parsing rnn/midi_songs\\HighwindTakestotheSkies.mid\n",
      "Parsing rnn/midi_songs\\In_Zanarkand.mid\n",
      "Parsing rnn/midi_songs\\JENOVA.mid\n",
      "Parsing rnn/midi_songs\\Kingdom_Hearts_Dearly_Beloved.mid\n",
      "Parsing rnn/midi_songs\\Kingdom_Hearts_Traverse_Town.mid\n",
      "Parsing rnn/midi_songs\\Life_Stream.mid\n",
      "Parsing rnn/midi_songs\\lurk_in_dark.mid\n",
      "Parsing rnn/midi_songs\\mining.mid\n",
      "Parsing rnn/midi_songs\\Oppressed.mid\n",
      "Parsing rnn/midi_songs\\OTD5YA.mid\n",
      "Parsing rnn/midi_songs\\path_of_repentance.mid\n",
      "Parsing rnn/midi_songs\\pkelite4.mid\n",
      "Parsing rnn/midi_songs\\Rachel_Piano_tempofix.mid\n",
      "Parsing rnn/midi_songs\\redwings.mid\n",
      "Parsing rnn/midi_songs\\relmstheme-piano.mid\n",
      "Parsing rnn/midi_songs\\roseofmay-piano.mid\n",
      "Parsing rnn/midi_songs\\rufus.mid\n",
      "Parsing rnn/midi_songs\\Rydia_pc.mid\n",
      "Parsing rnn/midi_songs\\sandy.mid\n",
      "Parsing rnn/midi_songs\\sera_.mid\n",
      "Parsing rnn/midi_songs\\sobf.mid\n",
      "Parsing rnn/midi_songs\\Still_Alive-1.mid\n",
      "Parsing rnn/midi_songs\\Suteki_Da_Ne_(Piano_Version).mid\n",
      "Parsing rnn/midi_songs\\thenightmarebegins.mid\n",
      "Parsing rnn/midi_songs\\thoughts.mid\n",
      "Parsing rnn/midi_songs\\tifap.mid\n",
      "Parsing rnn/midi_songs\\tpirtsd-piano.mid\n",
      "Parsing rnn/midi_songs\\traitor.mid\n",
      "Parsing rnn/midi_songs\\ultimafro.mid\n",
      "Parsing rnn/midi_songs\\ultros.mid\n",
      "Parsing rnn/midi_songs\\VincentPiano.mid\n",
      "Parsing rnn/midi_songs\\ViviinAlexandria.mid\n",
      "Parsing rnn/midi_songs\\waltz_de_choco.mid\n",
      "Parsing rnn/midi_songs\\Zelda_Overworld.mid\n",
      "Parsing rnn/midi_songs\\z_aeristhemepiano.mid\n"
     ]
    }
   ],
   "source": [
    "notes = get_notes(data_path)\n",
    "\n",
    "n_vocab = len(set(notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "voluntary-accreditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing dataset for the model\n",
    "def prepare_sequences(notes, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    sequence_length = 100\n",
    "\n",
    "    # get all pitch names\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "\n",
    "     # create a dictionary to map pitches to integers\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    # create input sequences and the corresponding outputs\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "\n",
    "    network_output = to_categorical(network_output)\n",
    "\n",
    "    return (network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "boring-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_input, network_output = prepare_sequences(notes, n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "skilled-venue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 100, 512)          1052672   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 512)          2099200   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 308)               79156     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 308)               0         \n",
      "=================================================================\n",
      "Total params: 5,464,628\n",
      "Trainable params: 5,463,092\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the structure of the model\n",
    "model = Sequential()\n",
    "model.add(LSTM(\n",
    "    512,\n",
    "    input_shape=(network_input.shape[1], network_input.shape[2]),\n",
    "    recurrent_dropout=0.3,\n",
    "    return_sequences=True\n",
    "))\n",
    "model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
    "model.add(LSTM(512))\n",
    "model.add(BatchNorm())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNorm())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(n_vocab))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-pitch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 43990 samples\n",
      "14080/43990 [========>.....................] - ETA: 1:12:56 - loss: 4.8411"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath,\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "history = model.fit(network_input, network_output, epochs=epochs, batch_size=batch_size, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "urban-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating notes from the neural network based on a sequence of notes\n",
    "def generate_notes(model, network_input, pitchnames, n_vocab):\n",
    "    \n",
    "    # pick a random sequence from the input as a starting point for the prediction\n",
    "    start = numpy.random.randint(0, len(network_input)-1)\n",
    "\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    pattern = network_input[start]\n",
    "    prediction_output = []\n",
    "\n",
    "    for note_index in range(generated_note_size):\n",
    "        prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "        prediction_input = prediction_input / float(n_vocab)\n",
    "\n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "\n",
    "        index = numpy.argmax(prediction)\n",
    "        result = int_to_note[index]\n",
    "        prediction_output.append(result)\n",
    "\n",
    "        pattern = numpy.append(pattern, index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "\n",
    "    return prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-occupation",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitchnames = sorted(set(item for item in notes))\n",
    "prediction_output = generate_notes(model, network_input, pitchnames, n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-quarter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the output from the prediction to notes\n",
    "# and create a midi file from the notes\n",
    "def create_midi(prediction_output):\n",
    "    \n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        # pattern is a note\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 0.5\n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "\n",
    "    midi_stream.write('midi', fp='test_output.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-rochester",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_midi(prediction_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
